---
type: lecture
date: 2025-09-05T11:00:00
title: "Lecture 4: Supervised, Unsupervised and Semi-supervised"
tldr: "ML Part II - Data"
stat: lec
# for lectures stat: lec
description: We give a simple example of unsupervised learning. We also take a look at other possible cases. 
videoID:  2Pe5J87fhUs 
hide_from_announcments: false
---
**Lecture Notes:**
- [Chapter 1 - Section 2]({{ site.baseurl }}/assets/Notes/CH1/CH1_Sec2.pdf) 

<!-- **Further Reads:**
* [Tokenization](https://web.stanford.edu/~jurafsky/slp3/2.pdf): Chapter 2 of [[JM]](https://web.stanford.edu/~jurafsky/slp3/)
* [Embedding](https://web.stanford.edu/~jurafsky/slp3/6.pdf): Chapter 6 of [[JM]](https://web.stanford.edu/~jurafsky/slp3/)
* [Original BPE Algorithm](http://www.pennelynn.com/Documents/CUJ/HTML/94HTML/19940045.HTM): Original BPE Algorithm proposed by Philip Gage in 1994
* [BPE for Tokenization](https://arxiv.org/abs/1508.07909): Paper _Neural machine translation of rare words with subword units_ by _Rico Sennrich, Barry Haddow, and Alexandra Birch_ presented in ACL 2016 that adapted BPE for NLP -->