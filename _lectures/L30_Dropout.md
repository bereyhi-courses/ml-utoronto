---
type: lecture
date: 2025-10-07T12:30:00
title: "Lecture 30: Dropout"
tldr: "Dropout"
stat: lec
# for lectures stat: lec
description: Dropout is a special form of regularization in which we randomly drop neurons in each iteration. We talk about the dropout and learn how we can implement it.  
videoID: 5IJZM35r4S8 
hide_from_announcments: false
---
**Lecture Notes:**
- [Chapter 3 - Section 2]({{ site.baseurl }}/assets/Notes/CH3/CH3_Sec2.pdf) 

**Further Reads:**
* [Dropout 1](https://arxiv.org/abs/1207.0580) Paper _Improving neural networks by preventing co-adaptation of feature detectors_ published in 2012 by _G. Hinton et al._ proposing Dropout
* [Dropout 2](https://jmlr.org/papers/v15/srivastava14a.html) Paper _Dropout: A Simple Way to Prevent Neural Networks from Overfitting_ published in 2014 by _N. Srivastava et al._ providing some analysis and illustrations on Dropout