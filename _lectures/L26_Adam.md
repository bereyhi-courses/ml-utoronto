---
type: lecture
date: 2025-10-03T11:40:00
title: "Lecture 26: RMSprop and Adam"
tldr: "Optimizers - Part III"
stat: lec
# for lectures stat: lec
description: We discuss two important optimizers, the Root Mean Square propagation (RMSprop) and Adam. We see that they both use the ideas of moving average and dimension dependent scheduling. 
videoID: Gl8u5GpKK-E 
hide_from_announcments: false
---
**Lecture Notes:**
- [Chapter 3 - Section 1]({{ site.baseurl }}/assets/Notes/CH3/CH3_Sec1.pdf) 

**Further Reads:**
* [RMSprop](https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf) Lecture note by _GEoffrey Hinton_ proposing RMSprop
* [RMSprop Analysis](https://arxiv.org/abs/1502.04390v1) Paper _RMSProp and equilibrated adaptive learning rates for non-convex optimization_ by _Y. Dauphin et al._ published in 2015 talking about RMSprop and citing  Honton's lecture notes
* [Adam](https://arxiv.org/abs/1412.6980) Paper _Adam: A Method for Stochastic Optimization_ published in 2014 by _D. Kingma and J. Ba_ proposing Adam