---
type: lecture
date: 2025-09-30T12:15:00
title: "Lecture 24: Linear and Sub-linear Convergence Speed"
tldr: "Optimizers - Part I"
stat: lec
# for lectures stat: lec
description: We get a bit of discussions on convergence of optimizers. There are two set of speeds, linear and sub-linear. While the linear is very appreciated, it does not happen in practice. This motivates us to study efficient optimizers. 
videoID: lF1ZufXEegE 
hide_from_announcments: false
---
**Lecture Notes:**
- [Chapter 3 - Section 1]({{ site.baseurl }}/assets/Notes/CH3/CH3_Sec1.pdf) 

**Further Reads:**
* [Notes on Optimizers](https://optmlclass.github.io/notes/optforml_notes.pdf) Lecture notes of the course _Optimization for Machine Learning_ by _Ashok Cutkosky_ in _Boston University_: A good resource for optimizers